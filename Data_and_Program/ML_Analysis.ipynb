{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINAL PROJECT - JEN, THEA, SARATH \n",
    "### --- DATING ANALYSIS ---\n",
    "### PREDICT WHETHER DATERS WANT TO MEET AGAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as pltt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, fbeta_score\n",
    "scorer = make_scorer(fbeta_score, beta=1.5)\n",
    "\n",
    "# Some warnings tend to pop up during grid search\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8378 observations and 195 features\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Data/Speed_Dating_Data.csv', encoding='latin-1', engine=\"python\")\n",
    "\n",
    "print(data.shape[0], 'observations and', data.shape[1], 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    174\n",
       "int64       13\n",
       "object       8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What kind of data are we dealing with?\n",
    "data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    277\n",
       "0.0    274\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Men (1) and women (0)\n",
    "data.groupby('iid').mean().gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.835283\n",
       "1    0.164717\n",
       "Name: match, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What percentage of pairs resulted in a match?\n",
    "data['match'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>idg</th>\n",
       "      <th>condtn</th>\n",
       "      <th>wave</th>\n",
       "      <th>round</th>\n",
       "      <th>position</th>\n",
       "      <th>positin1</th>\n",
       "      <th>order</th>\n",
       "      <th>...</th>\n",
       "      <th>attr3_3</th>\n",
       "      <th>sinc3_3</th>\n",
       "      <th>intel3_3</th>\n",
       "      <th>fun3_3</th>\n",
       "      <th>amb3_3</th>\n",
       "      <th>attr5_3</th>\n",
       "      <th>sinc5_3</th>\n",
       "      <th>intel5_3</th>\n",
       "      <th>fun5_3</th>\n",
       "      <th>amb5_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   iid   id  gender  idg  condtn  wave  round  position  positin1  order  ...  \\\n",
       "0    1  1.0       0    1       1     1     10         7       NaN      4  ...   \n",
       "1    1  1.0       0    1       1     1     10         7       NaN      3  ...   \n",
       "2    1  1.0       0    1       1     1     10         7       NaN     10  ...   \n",
       "3    1  1.0       0    1       1     1     10         7       NaN      5  ...   \n",
       "4    1  1.0       0    1       1     1     10         7       NaN      7  ...   \n",
       "\n",
       "   attr3_3  sinc3_3  intel3_3  fun3_3  amb3_3  attr5_3  sinc5_3  intel5_3  \\\n",
       "0      5.0      7.0       7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "1      5.0      7.0       7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "2      5.0      7.0       7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "3      5.0      7.0       7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "4      5.0      7.0       7.0     7.0     7.0      NaN      NaN       NaN   \n",
       "\n",
       "   fun5_3  amb5_3  \n",
       "0     NaN     NaN  \n",
       "1     NaN     NaN  \n",
       "2     NaN     NaN  \n",
       "3     NaN     NaN  \n",
       "4     NaN     NaN  \n",
       "\n",
       "[5 rows x 195 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waves 6-11 rated importance, others allocated 100 points\n",
    "points = (data.wave != 6 ) &\\\n",
    "    (data.wave != 7 ) &\\\n",
    "    (data.wave != 8 ) &\\\n",
    "    (data.wave != 9 ) &\\\n",
    "    (data.wave != 10 ) &\\\n",
    "    (data.wave != 11 )\n",
    "\n",
    "data = data[points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['match', 'dec_o', 'dec', 'like_o', 'like', 'fun_o', 'fun', 'shar_o',\n",
       "       'shar', 'attr_o', 'attr', 'prob_o', 'prob'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_corrs = data.select_dtypes(include=[np.number])\\\n",
    ".corrwith(data.match)\\\n",
    ".sort_values(ascending=False)\n",
    "\n",
    "match_corrs = match_corrs[match_corrs > .25].index\n",
    "\n",
    "data = data.dropna(subset=['id', 'pid'], axis=0)\n",
    "\n",
    "for i in match_corrs[1:]:\n",
    "    del data[i]\n",
    "\n",
    "# Other columns that are too predictive\n",
    "del data['int_corr']\n",
    "del data['them_cal']\n",
    "del data['you_call']\n",
    "\n",
    "del data['field'] # redundant\n",
    "\n",
    "match_corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_numeric(col, df=data, median=False):\n",
    "    try:\n",
    "        df[col] = df[col].str.replace(',', '')\n",
    "    except:\n",
    "        print('Column is not a string!')\n",
    "    \n",
    "    df[col] = df[col].astype(float)\n",
    "    \n",
    "    if median:\n",
    "        df[col] = df[col].fillna(data.fillna.median())\n",
    "    \n",
    "    else:\n",
    "        df[col] = df[col].fillna(-100)\n",
    "    \n",
    "    return df\n",
    "\n",
    "for i in 'zipcode mn_sat tuition income'.split():\n",
    "    data = fix_numeric(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undergra, from, career, "
     ]
    }
   ],
   "source": [
    "for i in data.columns:\n",
    "    if data[i].dtype == \"O\":\n",
    "        data[i] = data[i].str.lower()\n",
    "        print(i, end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Benchmark: 0.39567670124395443\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "data_benchmark = pd.get_dummies(data)\n",
    "data_benchmark.fillna(data_benchmark.median(), inplace=True)\n",
    "\n",
    "xbench = data_benchmark.drop('match', axis=1)\n",
    "ybench = data_benchmark['match']\n",
    "\n",
    "dum = DummyClassifier(strategy='constant', constant=1)\n",
    "\n",
    "cvs = cross_val_score(dum, xbench, ybench, scoring=scorer, cv=5)\n",
    "\n",
    "benchmark_score = cvs.mean()\n",
    "\n",
    "print('Naive Benchmark:', benchmark_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['from_new_england'] = 0\n",
    "for i in 'massachu connect rhode vermont vt hampsh maine boston cambridge'.split():\n",
    "    data['from_new_england'] = np.where((data['from'].str.contains(i)) |\\\n",
    "                                   (data['undergra'].str.contains(i)), 1,\n",
    "                                        data['from_new_england'])\n",
    "    \n",
    "data['from_china'] = 0\n",
    "for i in 'china beijing shanghai hong taiwan'.split():\n",
    "    data['from_china'] = np.where((data['from'].str.contains(i)) |\\\n",
    "                                  (data['undergra'].str.contains(i)), 1,\n",
    "                                  data['from_china'])\n",
    "\n",
    "data['from_india'] = 0\n",
    "for i in 'india delhi bangalore'.split():\n",
    "    data['from_india'] = np.where((data['from'].str.contains(i)) |\\\n",
    "                                  (data['undergra'].str.contains(i)), 1,\n",
    "                                  data['from_india'])\n",
    "    \n",
    "data['from_europe'] = 0\n",
    "for i in 'europe germany italy france spain poland portugal netherlands holland sweden switz greece belgium paris rome'.split():\n",
    "    data['from_europe'] = np.where((data['from'].str.contains(i)) |\\\n",
    "                                   (data['undergra'].str.contains(i)), 1,\n",
    "                                   data['from_europe'])\n",
    "\n",
    "data['from_uk'] = 0\n",
    "for i in 'london england uk britain scotland ireland kingdom oxford'.split():\n",
    "    data['from_uk'] = np.where((data['from'].str.contains(i)) |\\\n",
    "                                   (data['undergra'].str.contains(i)), 1,\n",
    "                               data['from_uk'])\n",
    "\n",
    "data['from_ny'] = 0\n",
    "for i in ['new york', 'ny']:\n",
    "    data['from_ny'] = np.where((data['from'].str.contains(i)) |\\\n",
    "                               (data['undergra'].str.contains(i)), 1,\n",
    "                               data['from_ny'])\n",
    "\n",
    "data['from_nj'] = 0\n",
    "for i in ['new jersey', 'nj']:\n",
    "    data['from_nj'] = np.where((data['from'].str.contains(i)) |\\\n",
    "                               (data['undergra'].str.contains(i)), 1,\n",
    "                               data['from_nj'])\n",
    "\n",
    "data['from_california'] = 0\n",
    "for i in 'cali diego francisco jose davis sacramento oakland clara angeles ucla stanford berkeley alto torrance'.split():\n",
    "    data['from_california'] = np.where((data['from'].str.contains(i)) |\\\n",
    "                                   (data['undergra'].str.contains(i)), 1,\n",
    "                                       data['from_california'])\n",
    "    \n",
    "data['from_texas'] = 0\n",
    "for i in 'texas tx dallas austin houston dfw antonio'.split():\n",
    "    data['from_texas'] = np.where((data['from'].str.contains(i)) |\\\n",
    "                                   (data['undergra'].str.contains(i)), 1,\n",
    "                                  data['from_texas'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['career_education'] = 0\n",
    "for i in 'professor teach academ educ'.split():\n",
    "    data['career_education'] = np.where(data['career'].str.contains(i),\n",
    "                                        1, data['career_education'])\n",
    "\n",
    "data['career_law'] = 0\n",
    "for i in 'law attorney legal defender counsel'.split():\n",
    "    data['career_law'] = np.where(data['career'].str.contains(i),\n",
    "                                  1, data['career_law'])\n",
    "\n",
    "data['career_medicine'] = 0\n",
    "for i in 'doctor dr physician md medical m.d. cardio dentist surg'.split():\n",
    "    data['career_medicine'] = np.where(data['career'].str.contains(i),\n",
    "                                       1, data['career_medicine'])\n",
    "\n",
    "data['career_business'] = 0\n",
    "for i in 'business mba m.b.a. consult manage ceo c.e.o. entre finance venture market strategy invest bank equity'.split():\n",
    "    data['career_business'] = np.where(data['career'].str.contains(i),\n",
    "                                       1, data['career_business'])\n",
    "    \n",
    "data['career_science'] = 0\n",
    "for i in 'sci research biolo chemi'.split():\n",
    "    data['career_science'] = np.where(data['career'].str.contains(i),\n",
    "                                      1, data['career_science'])\n",
    "\n",
    "data['career_gov'] = 0\n",
    "for i in 'gov diplo poli'.split():\n",
    "    data['career_gov'] = np.where(data['career'].str.contains(i),\n",
    "                                  1, data['career_gov'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['school_columbia'] = 0\n",
    "for i in 'columbia'.split():\n",
    "    data['school_columbia'] = np.where(data['undergra'].str.contains(i),\n",
    "                                       1, data['school_columbia'])\n",
    "\n",
    "# Ivy league and other prestigious schools\n",
    "data['school_ivy'] = 0\n",
    "for i in 'dartmouth cornell princeton penn yale brown harvard stanford mit berkeley oxford'.split():\n",
    "    data['school_ivy'] = np.where(data['undergra'].str.contains(i),\n",
    "                                  1, data['school_ivy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5761, 820)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dummify\n",
    "data = pd.get_dummies(data, prefix='dummy')\n",
    "\n",
    "# Some Stackoverflow code to fix duplicate column names\n",
    "cols = pd.Series(data.columns)\n",
    "\n",
    "for dup in data.columns.get_duplicates():\n",
    "    cols[data.columns.get_loc(dup)] =\\\n",
    "    [dup+'.'+str(d_idx) if d_idx!=0 else dup for d_idx in range(data.columns.get_loc(dup).sum())]\n",
    "\n",
    "data.columns = cols\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_in_3    5278\n",
       "numdat_3    5067\n",
       "shar4_3     4271\n",
       "attr7_3     4271\n",
       "sinc7_3     4271\n",
       "intel7_3    4271\n",
       "fun7_3      4271\n",
       "amb7_3      4271\n",
       "attr4_3     4271\n",
       "sinc4_3     4271\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just a sample of how much missing data we have.\n",
    "data.isnull().sum().sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intel3_1 has 100 missing values\n",
      "regressing intel3_1 with an r2 of 0.998\n",
      "\n",
      "amb3_1 has 100 missing values\n",
      "regressing amb3_1 with an r2 of 0.998\n",
      "\n",
      "attr5_1 has 1900 missing values\n",
      "regressing attr5_1 with an r2 of 0.997\n",
      "\n",
      "sinc5_1 has 1900 missing values\n",
      "regressing sinc5_1 with an r2 of 0.981\n",
      "\n",
      "intel5_1 has 1900 missing values\n",
      "regressing intel5_1 with an r2 of 0.994\n",
      "\n",
      "fun5_1 has 1900 missing values\n",
      "regressing fun5_1 with an r2 of 0.993\n",
      "\n",
      "amb5_1 has 1900 missing values\n",
      "regressing amb5_1 with an r2 of 0.995\n",
      "\n",
      "sinc has 232 missing values\n",
      "regressing sinc with an r2 of 0.219\n",
      "\n",
      "intel has 242 missing values\n",
      "regressing intel with an r2 of 0.285\n",
      "\n",
      "amb has 505 missing values\n",
      "regressing amb with an r2 of 0.26\n",
      "\n",
      "met has 314 missing values\n",
      "regressing met with an r2 of 0.898\n",
      "\n",
      "match_es has 538 missing values\n",
      "regressing match_es with an r2 of 0.988\n",
      "\n",
      "attr1_s has 4134 missing values\n",
      "regressing attr1_s with an r2 of 0.995\n",
      "\n",
      "sinc1_s has 4134 missing values\n",
      "regressing sinc1_s with an r2 of 0.99\n",
      "\n",
      "intel1_s has 4134 missing values\n",
      "regressing intel1_s with an r2 of 0.998\n",
      "\n",
      "fun1_s has 4134 missing values\n",
      "regressing fun1_s with an r2 of 0.977\n",
      "\n",
      "amb1_s has 4134 missing values\n",
      "regressing amb1_s with an r2 of 0.987\n",
      "\n",
      "shar1_s has 4134 missing values\n",
      "regressing shar1_s with an r2 of 0.975\n",
      "\n",
      "attr3_s has 4149 missing values\n",
      "regressing attr3_s with an r2 of 0.991\n",
      "\n",
      "sinc3_s has 4149 missing values\n",
      "regressing sinc3_s with an r2 of 0.993\n",
      "\n",
      "intel3_s has 4149 missing values\n",
      "regressing intel3_s with an r2 of 0.989\n",
      "\n",
      "fun3_s has 4149 missing values\n",
      "regressing fun3_s with an r2 of 0.996\n",
      "\n",
      "amb3_s has 4149 missing values\n",
      "regressing amb3_s with an r2 of 0.982\n",
      "\n",
      "satis_2 has 708 missing values\n",
      "regressing satis_2 with an r2 of 0.999\n",
      "\n",
      "length has 708 missing values\n",
      "regressing length with an r2 of 0.997\n",
      "\n",
      "numdat_2 has 738 missing values\n",
      "regressing numdat_2 with an r2 of 0.983\n",
      "\n",
      "attr7_2 has 3778 missing values\n",
      "regressing attr7_2 with an r2 of 0.999\n",
      "\n",
      "sinc7_2 has 3807 missing values\n",
      "regressing sinc7_2 with an r2 of 0.99\n",
      "\n",
      "intel7_2 has 3778 missing values\n",
      "regressing intel7_2 with an r2 of 0.996\n",
      "\n",
      "fun7_2 has 3778 missing values\n",
      "regressing fun7_2 with an r2 of 0.993\n",
      "\n",
      "amb7_2 has 3807 missing values\n",
      "regressing amb7_2 with an r2 of 0.988\n",
      "\n",
      "shar7_2 has 3788 missing values\n",
      "regressing shar7_2 with an r2 of 0.988\n",
      "\n",
      "attr1_2 has 726 missing values\n",
      "regressing attr1_2 with an r2 of 0.998\n",
      "\n",
      "sinc1_2 has 708 missing values\n",
      "regressing sinc1_2 with an r2 of 0.999\n",
      "\n",
      "intel1_2 has 708 missing values\n",
      "regressing intel1_2 with an r2 of 0.992\n",
      "\n",
      "fun1_2 has 708 missing values\n",
      "regressing fun1_2 with an r2 of 0.998\n",
      "\n",
      "amb1_2 has 708 missing values\n",
      "regressing amb1_2 with an r2 of 0.997\n",
      "\n",
      "shar1_2 has 708 missing values\n",
      "regressing shar1_2 with an r2 of 0.998\n",
      "\n",
      "attr4_2 has 2387 missing values\n",
      "regressing attr4_2 with an r2 of 0.995\n",
      "\n",
      "sinc4_2 has 2387 missing values\n",
      "regressing sinc4_2 with an r2 of 0.995\n",
      "\n",
      "intel4_2 has 2387 missing values\n",
      "regressing intel4_2 with an r2 of 0.999\n",
      "\n",
      "fun4_2 has 2387 missing values\n",
      "regressing fun4_2 with an r2 of 0.994\n",
      "\n",
      "amb4_2 has 2387 missing values\n",
      "regressing amb4_2 with an r2 of 0.994\n",
      "\n",
      "shar4_2 has 2387 missing values\n",
      "regressing shar4_2 with an r2 of 0.999\n",
      "\n",
      "attr2_2 has 2387 missing values\n",
      "regressing attr2_2 with an r2 of 0.995\n",
      "\n",
      "sinc2_2 has 2387 missing values\n",
      "regressing sinc2_2 with an r2 of 0.998\n",
      "\n",
      "intel2_2 has 2387 missing values\n",
      "regressing intel2_2 with an r2 of 0.994\n",
      "\n",
      "fun2_2 has 2387 missing values\n",
      "regressing fun2_2 with an r2 of 0.997\n",
      "\n",
      "amb2_2 has 2387 missing values\n",
      "regressing amb2_2 with an r2 of 0.991\n",
      "\n",
      "shar2_2 has 2387 missing values\n",
      "regressing shar2_2 with an r2 of 0.997\n",
      "\n",
      "attr3_2 has 708 missing values\n",
      "regressing attr3_2 with an r2 of 0.995\n",
      "\n",
      "sinc3_2 has 708 missing values\n",
      "regressing sinc3_2 with an r2 of 0.992\n",
      "\n",
      "intel3_2 has 708 missing values\n",
      "regressing intel3_2 with an r2 of 0.998\n",
      "\n",
      "fun3_2 has 708 missing values\n",
      "regressing fun3_2 with an r2 of 0.995\n",
      "\n",
      "amb3_2 has 708 missing values\n",
      "regressing amb3_2 with an r2 of 0.993\n",
      "\n",
      "attr5_2 has 2387 missing values\n",
      "regressing attr5_2 with an r2 of 0.994\n",
      "\n",
      "sinc5_2 has 2387 missing values\n",
      "regressing sinc5_2 with an r2 of 0.997\n",
      "\n",
      "intel5_2 has 2387 missing values\n",
      "regressing intel5_2 with an r2 of 0.996\n",
      "\n",
      "fun5_2 has 2387 missing values\n",
      "regressing fun5_2 with an r2 of 0.998\n",
      "\n",
      "amb5_2 has 2387 missing values\n",
      "regressing amb5_2 with an r2 of 0.992\n",
      "\n",
      "date_3 has 3261 missing values\n",
      "regressing date_3 with an r2 of 0.998\n",
      "\n",
      "numdat_3 has 5067 missing values\n",
      "regressing numdat_3 with an r2 of 0.997\n",
      "\n",
      "num_in_3 has 5278 missing values\n",
      "regressing num_in_3 with an r2 of 1.0\n",
      "\n",
      "attr1_3 has 3261 missing values\n",
      "regressing attr1_3 with an r2 of 0.987\n",
      "\n",
      "sinc1_3 has 3261 missing values\n",
      "regressing sinc1_3 with an r2 of 0.999\n",
      "\n",
      "intel1_3 has 3261 missing values\n",
      "regressing intel1_3 with an r2 of 0.997\n",
      "\n",
      "fun1_3 has 3261 missing values\n",
      "regressing fun1_3 with an r2 of 0.992\n",
      "\n",
      "amb1_3 has 3261 missing values\n",
      "regressing amb1_3 with an r2 of 0.999\n",
      "\n",
      "shar1_3 has 3261 missing values\n",
      "regressing shar1_3 with an r2 of 0.998\n",
      "\n",
      "attr7_3 has 4271 missing values\n",
      "regressing attr7_3 with an r2 of 0.998\n",
      "\n",
      "sinc7_3 has 4271 missing values\n",
      "regressing sinc7_3 with an r2 of 0.993\n",
      "\n",
      "intel7_3 has 4271 missing values\n",
      "regressing intel7_3 with an r2 of 0.981\n",
      "\n",
      "fun7_3 has 4271 missing values\n",
      "regressing fun7_3 with an r2 of 0.989\n",
      "\n",
      "amb7_3 has 4271 missing values\n",
      "regressing amb7_3 with an r2 of 0.99\n",
      "\n",
      "shar7_3 has 4271 missing values\n",
      "regressing shar7_3 with an r2 of 0.996\n",
      "\n",
      "attr4_3 has 4271 missing values\n",
      "regressing attr4_3 with an r2 of 0.984\n",
      "\n",
      "sinc4_3 has 4271 missing values\n",
      "regressing sinc4_3 with an r2 of 0.992\n",
      "\n",
      "intel4_3 has 4271 missing values\n",
      "regressing intel4_3 with an r2 of 0.996\n",
      "\n",
      "fun4_3 has 4271 missing values\n",
      "regressing fun4_3 with an r2 of 0.98\n",
      "\n",
      "amb4_3 has 4271 missing values\n",
      "regressing amb4_3 with an r2 of 0.999\n",
      "\n",
      "shar4_3 has 4271 missing values\n",
      "regressing shar4_3 with an r2 of 0.998\n",
      "\n",
      "attr2_3 has 4271 missing values\n",
      "regressing attr2_3 with an r2 of 0.994\n",
      "\n",
      "sinc2_3 has 4271 missing values\n",
      "regressing sinc2_3 with an r2 of 0.993\n",
      "\n",
      "intel2_3 has 4271 missing values\n",
      "regressing intel2_3 with an r2 of 0.999\n",
      "\n",
      "fun2_3 has 4271 missing values\n",
      "regressing fun2_3 with an r2 of 0.998\n",
      "\n",
      "amb2_3 has 4271 missing values\n",
      "regressing amb2_3 with an r2 of 0.991\n",
      "\n",
      "shar2_3 has 4271 missing values\n",
      "regressing shar2_3 with an r2 of 0.989\n",
      "\n",
      "attr3_3 has 3261 missing values\n",
      "regressing attr3_3 with an r2 of 0.99\n",
      "\n",
      "sinc3_3 has 3261 missing values\n",
      "regressing sinc3_3 with an r2 of 1.0\n",
      "\n",
      "intel3_3 has 3261 missing values\n",
      "regressing intel3_3 with an r2 of 0.998\n",
      "\n",
      "fun3_3 has 3261 missing values\n",
      "regressing fun3_3 with an r2 of 0.997\n",
      "\n",
      "amb3_3 has 3261 missing values\n",
      "regressing amb3_3 with an r2 of 0.998\n",
      "\n",
      "attr5_3 has 4271 missing values\n",
      "regressing attr5_3 with an r2 of 0.972\n",
      "\n",
      "sinc5_3 has 4271 missing values\n",
      "regressing sinc5_3 with an r2 of 0.982\n",
      "\n",
      "intel5_3 has 4271 missing values\n",
      "regressing intel5_3 with an r2 of 0.997\n",
      "\n",
      "fun5_3 has 4271 missing values\n",
      "regressing fun5_3 with an r2 of 0.999\n",
      "\n",
      "amb5_3 has 4271 missing values\n",
      "regressing amb5_3 with an r2 of 0.997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "# Get null columns\n",
    "null_cols = data.isnull().sum()\n",
    "null_cols = list(null_cols[null_cols != 0].index)\n",
    "\n",
    "for i in null_cols:\n",
    "    print(i, 'has', data[i].isnull().sum(), 'missing values')\n",
    "    x = data.fillna(data[i].mean()).drop(['match', 'id'], axis=1)\n",
    "    y = x.pop(i)\n",
    "    \n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=.2)\n",
    "    reg = KNeighborsRegressor()\n",
    "    reg.fit(xtrain, ytrain)      \n",
    "    pred = reg.predict(xtest)\n",
    "    r2 = r2_score(ytest, pred)\n",
    "    \n",
    "    # If we can reasonably predict these values, do so\n",
    "    if r2 > .2:\n",
    "        print('regressing', i, 'with an r2 of', round(r2, 3))\n",
    "        data['predicted'] = reg.predict(data.fillna(data[i].median()).drop([i, 'match', 'id'], axis=1))\n",
    "        data[i] = np.where(data[i].isnull(), data['predicted'], data[i])\n",
    "        del data['predicted']\n",
    "    \n",
    "    # Otherwise, just take the median\n",
    "    else:\n",
    "        print('averaging', i)\n",
    "        data[i] = data[i].fillna(data[i].median())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partner_data(pid, col):\n",
    "    '''Looks up the person's partner and adds their data\n",
    "    as new features. If the partner ID doesn't exist,\n",
    "    returns a -1.'''\n",
    "    try:\n",
    "        partner = data[data['iid'] == pid].head(1)[col].iloc[0]\n",
    "        if partner:\n",
    "            return partner\n",
    "        else:\n",
    "            return -1\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "# Income (where income data is available, take the log difference)\n",
    "data['partner_income'] = data['pid'].apply(get_partner_data, col='income')\n",
    "data['income_difference'] = np.where((data.partner_income == -1) |\\\n",
    "                                     (data.income == -1),\n",
    "                                     -1, np.log1p(np.abs(data.income - data.partner_income)))\n",
    "\n",
    "# Age\n",
    "data['age'].fillna(data['age'].median(), inplace=True)\n",
    "data['age_o'].fillna(data['age_o'].median(), inplace=True)\n",
    "data['age_difference'] = data['age'] - data['age_o']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
